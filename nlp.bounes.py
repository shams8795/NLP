# -*- coding: utf-8 -*-
"""Untitled68.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XZZS8YqW4dgU_OyjU9Zgm3NLBcf1TLKQ
"""

!pip install -U datasets

from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
import torch
from datasets import load_dataset
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

dataset = load_dataset("lex_glue", "ecthr_a")  # أو "ledgar"/"scotus" حسب اختيارك

from transformers import pipeline

classifier = pipeline("text-generation", model="gpt2")

# 1. تحميل البيانات
from datasets import load_dataset
dataset = load_dataset("lex_glue", "ledgar")  # أو "scotus"

# 2. أخذ عينة نصية
example_text = dataset["test"][0]["text"]  # أو "train" بدلاً من "test" لو حبيتي

# 3. تحميل نموذج توليد النصوص
from transformers import pipeline
classifier = pipeline("text-generation", model="gpt2")

# 4. بناء البرومبت
prompt = (
    "Given the following legal document, classify it into one of the categories "
    "(e.g., Contract, Memo, Agreement):\n\n"
    f"Document:\n{example_text}\n\nLabel:"
)

# 5. استخدام النموذج للتصنيف
output = classifier(prompt, max_new_tokens=15)
print(output[0]["generated_text"])

model_name = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize(batch):
    return tokenizer(batch["text"], padding="max_length", truncation=True)

tokenized_dataset = dataset.map(tokenize, batched=True)

!pip install -U transformers

# استكشاف القيم الفعلية لليبلات
print("✅ Labels summary:")
print("Train labels:", torch.unique(train_dataset["labels"]))
print("Max label:", torch.max(train_dataset["labels"]))
print("Min label:", torch.min(train_dataset["labels"]))
print("num_labels to be used:", int(torch.max(train_dataset["labels"]).item()) + 1)

# فلترة test: نخلي بس الأمثلة اللي labelها موجود في التدريب
valid_labels = set(all_labels)
small_test_dataset = small_test_dataset.filter(lambda example: example["label"] in valid_labels)

test_labels = label_encoder.transform(small_test_dataset["label"])
small_test_dataset = small_test_dataset.remove_columns("label")
small_test_dataset = small_test_dataset.add_column("label", test_labels)

# ✅ 1. تثبيت المكتبات (لو مش متوفرة)
!pip install datasets scikit-learn

# ✅ 2. استيراد المكتبات
from datasets import load_dataset
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.pipeline import Pipeline

# ✅ 3. تحميل البيانات (عينة صغيرة)
dataset = load_dataset("lex_glue", "ledgar")
train_texts = dataset["train"]["text"][:1000]
train_labels = dataset["train"]["label"][:1000]
test_texts = dataset["test"]["text"][:200]
test_labels = dataset["test"]["label"][:200]

# ✅ 4. ترميز التصنيفات لتكون أرقام متسلسلة
le = LabelEncoder()
train_labels_enc = le.fit_transform(train_labels)
test_labels_enc = le.transform([lbl for lbl in test_labels if lbl in le.classes_])

# ✅ 5. تصفية test_texts من أي label غير معروف
filtered_test_texts = [text for text, label in zip(test_texts, test_labels) if label in le.classes_]

# ✅ 6. إنشاء نموذج Logistic Regression داخل pipeline
clf = Pipeline([
    ("tfidf", TfidfVectorizer(max_features=3000)),
    ("logreg", LogisticRegression(max_iter=1000))
])

# ✅ 7. تدريب النموذج
clf.fit(train_texts, train_labels_enc)

# ✅ 8. التنبؤ والتقييم
preds = clf.predict(filtered_test_texts)
print("\n📋 Classification Report (Logistic Regression):")
print(classification_report(test_labels_enc, preds, digits=2))

!pip install datasets transformers scikit-learn

!pip install datasets

from datasets import load_dataset
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

# 1. تحميل البيانات
dataset = load_dataset("lex_glue", "ledgar")
texts = dataset["train"]["text"][:1000]
labels = dataset["train"]["label"][:1000]

# 2. تقسيم البيانات (بدون stratify)
X_train, X_test, y_train, y_test = train_test_split(
    texts, labels, test_size=0.2, random_state=42
)

# 3. تحويل النصوص إلى TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# 4. تدريب النماذج
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Naive Bayes": MultinomialNB(),
    "Random Forest": RandomForestClassifier(n_estimators=100)
}

# 5. تقييم كل نموذج
for name, model in models.items():
    print(f"🔹 {name}")
    model.fit(X_train_tfidf, y_train)
    preds = model.predict(X_test_tfidf)
    print(classification_report(y_test, preds))
    print("="*60)

import matplotlib.pyplot as plt

# القيم من تقرير التصنيف
metrics = ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1', 'Weighted Precision', 'Weighted Recall', 'Weighted F1']
values = [0.67, 0.52, 0.57, 0.52, 0.63, 0.67, 0.62]

# رسم الرسم البياني
plt.figure(figsize=(10, 6))
bars = plt.bar(metrics, values)
plt.ylim(0, 1)
plt.title("Classification Metrics for Logistic Regression")
plt.ylabel("Score")
plt.xticks(rotation=45)
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f"{yval:.2f}", ha='center', va='bottom')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# بيانات المقارنة بين النموذجين (مثال، استبدلها بالقيم الحقيقية)
model_names = ["TF-IDF + Logistic", "BERT"]
accuracy = [0.53, 0.67]
precision = [0.41, 0.50]
recall = [0.53, 0.56]
f1 = [0.43, 0.50]

# الرسم البياني
x = range(len(model_names))
width = 0.2

plt.figure(figsize=(10, 6))
plt.bar([i - 1.5 * width for i in x], accuracy, width, label="Accuracy")
plt.bar([i - 0.5 * width for i in x], precision, width, label="Precision")
plt.bar([i + 0.5 * width for i in x], recall, width, label="Recall")
plt.bar([i + 1.5 * width for i in x], f1, width, label="F1 Score")

plt.xticks(x, model_names)
plt.ylabel("Score")
plt.ylim(0, 1)
plt.title("Model Comparison")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()